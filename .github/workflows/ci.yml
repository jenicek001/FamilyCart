# CI/CD Pipeline for FamilyCart
# 
# This workflow requires the following GitHub Secrets (Repository Settings ‚Üí Secrets and variables ‚Üí Actions):
#
# Required CI Infrastructure Secrets:
#   - CI_POSTGRES_USER: PostgreSQL username for CI database
#   - CI_POSTGRES_PASSWORD: PostgreSQL password for CI database  
#   - CI_POSTGRES_DB: PostgreSQL database name for CI
#   - CI_REDIS_PASSWORD: Redis password for CI cache
#   - CI_SECRET_KEY: Application secret key for JWT tokens
#   - GITHUB_TOKEN: Automatically provided by GitHub Actions
#
# Generate secure credentials with: ./scripts/generate-ci-credentials.sh
#
# UAT Environment (repository Settings ‚Üí Environments ‚Üí uat):
#   - UAT_HOST (optional): Remote UAT server hostname/IP
#   - UAT_USER (optional): Username for remote UAT server  
#   - UAT_SSH_KEY (optional): SSH private key for remote UAT server
#   - UAT_BASE_URL (optional): UAT frontend URL (default: http://localhost:3001)
#   - UAT_API_URL (optional): UAT backend URL (default: http://localhost:8001)
#
# Production Environment (repository Settings ‚Üí Environments ‚Üí production):
#   - PRODUCTION_SSH_KEY: SSH private key for production server
#   - PRODUCTION_HOST: Production server hostname/IP
#   - PRODUCTION_USER: Username for production server
#   - PRODUCTION_URL: Production application URL
#
# Note: If UAT_HOST/UAT_USER/UAT_SSH_KEY are not set, UAT deployment will run locally on the self-hosted runner

name: CI/CD

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: jenicek001/familycart

jobs:
  test:
    runs-on: self-hosted
    timeout-minutes: 45  # Prevent infinite hanging

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Validate required CI secrets
        run: |
          echo "üîê Validating required CI secrets are configured..."
          
          # List of required secrets
          MISSING_SECRETS=()
          
          if [ -z "${{ secrets.CI_POSTGRES_USER }}" ]; then
            MISSING_SECRETS+=("CI_POSTGRES_USER")
          fi
          
          if [ -z "${{ secrets.CI_POSTGRES_PASSWORD }}" ]; then
            MISSING_SECRETS+=("CI_POSTGRES_PASSWORD")
          fi
          
          if [ -z "${{ secrets.CI_POSTGRES_DB }}" ]; then
            MISSING_SECRETS+=("CI_POSTGRES_DB")
          fi
          
          if [ -z "${{ secrets.CI_REDIS_PASSWORD }}" ]; then
            MISSING_SECRETS+=("CI_REDIS_PASSWORD")
          fi
          
          if [ ${#MISSING_SECRETS[@]} -ne 0 ]; then
            echo "‚ùå Missing required GitHub secrets:"
            for secret in "${MISSING_SECRETS[@]}"; do
              echo "  - $secret"
            done
            echo ""
            echo "Please add these secrets in GitHub: Settings ‚Üí Secrets and variables ‚Üí Actions"
            echo "Or run: ./scripts/generate-ci-credentials.sh for setup instructions"
            exit 1
          fi
          
          echo "‚úÖ All required CI secrets are configured"

      - name: Monitor system resources before starting
        run: |
          echo "üìä Initial system resources:"
          free -h | grep -E '(Mem|Swap)'
          df -h / | tail -1
          echo "Available memory: $(free -m | awk '/^Mem:/{print $7}')"
          echo "Available disk: $(df -h / | awk 'NR==2{print $4}')"
          
          echo "üîß Docker system info:"
          docker system df || true
          
          echo "üßπ Safe Docker cleanup to prevent resource exhaustion..."
          # Stop containers that might consume resources, but EXCLUDE runner containers
          docker ps --filter "name!=familycart-runner" --filter "name!=runner" -q | xargs -r docker stop || true
          docker container prune -f || true
          # Safer image cleanup - only remove unused images older than 24h
          docker image prune -af --filter "until=24h" || true 
          # Skip volume pruning to avoid removing active volumes
          docker network prune -f || true
          # More conservative system prune without --volumes flag
          docker system prune -f || true
          
          echo "üõ°Ô∏è Setting resource limits in environment"
          # Limit Docker memory usage to prevent OOM kills
          echo "DOCKER_MEMORY_LIMIT=2g" >> $GITHUB_ENV
          echo "COMPOSE_PARALLEL_LIMIT=1" >> $GITHUB_ENV

      - name: Connect to CI infrastructure databases
        run: |
          echo "üîå Connecting to persistent CI infrastructure databases..."
          
          # Check if CI infrastructure services are available
          echo "ÔøΩ Checking CI infrastructure services..."
          
          # Test PostgreSQL connectivity
          echo "ÔøΩ Testing PostgreSQL connectivity..."
          for i in {1..10}; do
              if docker exec postgres-ci-familycart pg_isready -U ${{ secrets.CI_POSTGRES_USER }} -d ${{ secrets.CI_POSTGRES_DB }}; then
              echo "‚úÖ PostgreSQL is available!"
              break
            fi
            echo "PostgreSQL not ready, waiting... ($i/10)"
            sleep 2
            if [ $i -eq 10 ]; then
              echo "‚ùå PostgreSQL not available. Please ensure CI infrastructure is running:"
              echo "   docker compose -f docker-compose.ci-infrastructure.yml up -d"
              exit 1
            fi
          done
          
          # Test Redis connectivity
          echo "üì° Testing Redis connectivity..."
          for i in {1..5}; do
            if docker exec redis-ci-familycart redis-cli -a "${{ secrets.CI_REDIS_PASSWORD }}" ping | grep -q PONG; then
              echo "‚úÖ Redis is available!"
              break
            fi
            echo "Redis not ready, waiting... ($i/5)"
            sleep 1
            if [ $i -eq 5 ]; then
              echo "‚ùå Redis not available. Please ensure CI infrastructure is running:"
              echo "   docker compose -f docker-compose.ci-infrastructure.yml up -d"
              exit 1
            fi
          done
          
          echo "‚úÖ All CI infrastructure databases are ready!"

      - name: Verify Python installation
        run: |
          echo "Using pre-installed Python 3.12 from Ubuntu 24.04 runner"
          python3 --version
          which python3

      - name: Verify database containers are running
        run: |
          echo "üê≥ Verifying CI infrastructure containers are running..."
          docker ps --filter "name=postgres-ci-familycart" --filter "name=redis-ci-familycart"
          echo "‚úÖ Database containers verified!"

      - name: Configure Poetry (pre-installed)
        run: |
          echo "Poetry is pre-installed in our custom Ubuntu 24.04 runners"
          poetry --version
          poetry config virtualenvs.create true
          poetry config virtualenvs.in-project true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: backend/.venv
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}-with-dev

      - name: Install backend dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        working-directory: ./backend
        run: |
          echo "üì¶ Installing backend dependencies with code quality tools..."
          poetry install --no-interaction --no-root --with dev
          echo "‚úÖ Dependencies installed successfully!"

      - name: Run backend code quality checks
        working-directory: ./backend
        run: |
          echo "üîç Running code quality checks with balanced standards..."
          
          echo "=== Black Code Formatting ==="
          poetry run black --check .
          
          echo "=== Import Sorting ==="
          poetry run isort --check-only .
          
          echo "=== Pylint Code Quality ==="
          # Use balanced approach: check score but allow warnings
          PYLINT_OUTPUT=$(poetry run pylint app/ --rcfile=pyproject.toml --score=y 2>&1) || PYLINT_EXIT_CODE=$?
          echo "$PYLINT_OUTPUT"
          
          # Extract score from output
          PYLINT_SCORE=$(echo "$PYLINT_OUTPUT" | grep -oP "Your code has been rated at \K[\d\.]+" || echo "0")
          echo "üìä Pylint score: $PYLINT_SCORE/10"
          
          # Check if score meets our threshold (9.0/10) using Python
          SCORE_CHECK=$(python3 -c "print('pass' if float('$PYLINT_SCORE') >= 9.0 else 'fail')")
          if [ "$SCORE_CHECK" = "pass" ]; then
            echo "‚úÖ Pylint quality check passed: $PYLINT_SCORE/10 (threshold: 9.0/10)"
          else
            echo "‚ùå Pylint quality check failed: $PYLINT_SCORE/10 (threshold: 9.0/10)"
            exit 1
          fi
          
          echo "‚úÖ Code quality checks completed successfully!"
          
      - name: Run backend security scan
        working-directory: ./backend
        run: |
          echo "üîí Running security scan with balanced criteria..."
          
          # Run bandit with our configured standards
          poetry run bandit -c pyproject.toml -r app/
          
          # Optional: Generate report for analysis (don't fail on issues)
          poetry run bandit -c pyproject.toml -r app/ -f json -o bandit-report.json || true
          
          echo "‚úÖ Security scan completed successfully!"

      - name: Generate code quality report
        if: always()
        working-directory: ./backend
        run: |
          echo "üìä Generating comprehensive code quality report..."
          
          # Generate detailed pylint report
          poetry run pylint app/ --rcfile=pyproject.toml --output-format=json > pylint-report.json || true
          poetry run pylint app/ --rcfile=pyproject.toml --output-format=text > pylint-report.txt || true
          
          # Generate coverage report if not already done
          if [ ! -f coverage.xml ]; then
            poetry run pytest --cov=app --cov-report=xml --cov-report=html > /dev/null 2>&1 || true
          fi
          
          echo "‚úÖ Code quality report generated!"

      - name: Upload code quality artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-code-quality-reports
          path: |
            backend/pylint-report.json
            backend/pylint-report.txt
            backend/bandit-report.json
            backend/coverage.xml
            backend/htmlcov/
          retention-days: 30

      - name: Code quality summary
        if: always()
        working-directory: ./backend
        run: |
          echo "üìã Code Quality Summary:"
          echo "======================"
          
          # Extract pylint score if available
          if [ -f pylint-report.txt ]; then
            PYLINT_SCORE=$(grep -oP "Your code has been rated at \K[\d\.]+" pylint-report.txt || echo "N/A")
            echo "üîç Pylint Score: $PYLINT_SCORE/10"
          fi
          
          # Check if bandit found issues
          if [ -f bandit-report.json ]; then
            BANDIT_ISSUES=$(python3 -c "import json; data=json.load(open('bandit-report.json')); print(len(data.get('results', [])))" 2>/dev/null || echo "0")
            echo "üîí Security Issues: $BANDIT_ISSUES"
          fi
          
          # Coverage info
          if [ -f coverage.xml ]; then
            COVERAGE=$(python3 -c "import xml.etree.ElementTree as ET; tree=ET.parse('coverage.xml'); print(f'{float(tree.getroot().attrib[\"line-rate\"])*100:.1f}%')" 2>/dev/null || echo "N/A")
            echo "üìä Test Coverage: $COVERAGE"
          fi
          
          echo "======================"
          echo "‚úÖ Quality checks completed with balanced standards!"
          echo "üìÑ Reports available in artifacts"

      - name: Run backend tests with coverage
        working-directory: ./backend
        env:
          # Test database configuration - PostgreSQL for production parity
          POSTGRES_SERVER: postgres-ci-familycart
          POSTGRES_USER: ${{ secrets.CI_POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.CI_POSTGRES_PASSWORD }}
          POSTGRES_DB: ${{ secrets.CI_POSTGRES_DB }}
          POSTGRES_PORT: 5432
          # App configuration for tests
          SECRET_KEY: ${{ secrets.CI_SECRET_KEY || 'ci-test-secret-key-not-for-production-use-only' }}
          ALGORITHM: "HS256"
          ACCESS_TOKEN_EXPIRE_MINUTES: "30"
          REDIS_URI: "redis://:${{ secrets.CI_REDIS_PASSWORD }}@redis-ci-familycart:6379"
          CORS_ORIGINS: '["http://localhost:3000"]'
        run: |
          echo "üß™ Running backend tests with PostgreSQL..."
          
          # Wait for PostgreSQL to be ready using pg_isready
          echo "‚è≥ Waiting for PostgreSQL to be ready..."
          for i in {1..30}; do
            if pg_isready -h postgres-ci-familycart -p 5432 -U ${{ secrets.CI_POSTGRES_USER }}; then
              echo "‚úÖ PostgreSQL is ready!"
              break
            fi
            echo "PostgreSQL not ready, waiting... ($i/30)"
            sleep 2
          done
          
          # Test database connection
          echo "üîå Testing database connection..."
          PGPASSWORD=${{ secrets.CI_POSTGRES_PASSWORD }} psql -h postgres-ci-familycart -U ${{ secrets.CI_POSTGRES_USER }} -d ${{ secrets.CI_POSTGRES_DB }} -c "SELECT 1;" || {
            echo "‚ùå Failed to connect to PostgreSQL"
            exit 1
          }
          
          # Run database migrations if needed
          echo "üîÑ Running database migrations..."
          poetry run alembic upgrade head || echo "‚ö†Ô∏è No migrations to run"
          
          # Run tests with coverage
          echo "üß™ Running pytest with coverage..."
          poetry run pytest --cov=app --cov-report=xml --cov-report=html
          
      - name: Upload backend coverage to codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./backend/coverage.xml
          flags: backend
          name: backend-coverage
          
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci

      - name: Run frontend code quality checks
        working-directory: ./frontend
        run: |
          npm run lint
          npm run typecheck

      - name: Build frontend
        working-directory: ./frontend
        run: npm run build

      - name: Run frontend tests
        working-directory: ./frontend
        # Skip frontend tests if test script doesn't exist
        continue-on-error: true
        run: npm test -- --coverage --watchAll=false || echo "No frontend tests configured"

  security-scan:
    runs-on: self-hosted
    needs: test
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

  build:
    runs-on: self-hosted
    needs: [test, security-scan]
    outputs:
      backend-image: ${{ steps.meta-backend.outputs.tags }}
      frontend-image: ${{ steps.meta-frontend.outputs.tags }}
      backend-digest: ${{ steps.build-backend.outputs.digest }}
      frontend-digest: ${{ steps.build-frontend.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract backend metadata
        id: meta-backend
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push backend image
        id: build-backend
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: true
          tags: ${{ steps.meta-backend.outputs.tags }}
          labels: ${{ steps.meta-backend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

      - name: Extract frontend metadata
        id: meta-frontend
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push frontend image
        id: build-frontend
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          push: true
          tags: ${{ steps.meta-frontend.outputs.tags }}
          labels: ${{ steps.meta-frontend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

  deploy-uat:
    runs-on: self-hosted
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment: uat
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Deploy to UAT environment
        env:
          BACKEND_IMAGE: ${{ needs.build.outputs.backend-image }}
          FRONTEND_IMAGE: ${{ needs.build.outputs.frontend-image }}
          UAT_HOST: ${{ secrets.UAT_HOST }}
          UAT_USER: ${{ secrets.UAT_USER }}
          UAT_SSH_KEY: ${{ secrets.UAT_SSH_KEY }}
        run: |
          # Prepare SSH key if deploying to remote UAT
          if [ -n "$UAT_SSH_KEY" ] && [ -n "$UAT_HOST" ]; then
            echo "$UAT_SSH_KEY" > /tmp/uat_key
            chmod 600 /tmp/uat_key
            
            # Deploy to remote UAT server
            ssh -i /tmp/uat_key -o StrictHostKeyChecking=no $UAT_USER@$UAT_HOST << 'EOF'
              cd /opt/familycart-uat
              
              # Update Docker Compose with new images
              sed -i "s|ghcr.io/jenicek001/familycart-backend:.*|$BACKEND_IMAGE|g" docker-compose.uat.yml
              sed -i "s|ghcr.io/jenicek001/familycart-frontend:.*|$FRONTEND_IMAGE|g" docker-compose.uat.yml
              
              # Pull new images and deploy
              docker compose -f docker-compose.uat.yml pull
              docker compose -f docker-compose.uat.yml up -d --remove-orphans
              
              # Wait for services to start
              sleep 60
          EOF
            
            # Cleanup SSH key
            rm /tmp/uat_key
          else
            # Local UAT deployment (self-hosted runner)
            cd /opt/familycart-uat
            
            # Update Docker Compose with new images
            sed -i "s|ghcr.io/jenicek001/familycart-backend:.*|${BACKEND_IMAGE}|g" docker-compose.uat.yml
            sed -i "s|ghcr.io/jenicek001/familycart-frontend:.*|${FRONTEND_IMAGE}|g" docker-compose.uat.yml
            
            # Pull new images and deploy
            docker compose -f docker-compose.uat.yml pull
            docker compose -f docker-compose.uat.yml up -d --remove-orphans
            
            # Wait for services to start
            sleep 60
          fi
          
      - name: Health check UAT deployment
        env:
          UAT_BASE_URL: ${{ secrets.UAT_BASE_URL || 'http://localhost:3001' }}
          UAT_API_URL: ${{ secrets.UAT_API_URL || 'http://localhost:8001' }}
        run: |
          # Check backend health
          curl -f ${UAT_API_URL}/health || (echo "Backend health check failed" && exit 1)
          
          # Check frontend availability  
          curl -f ${UAT_BASE_URL}/ || (echo "Frontend health check failed" && exit 1)
          
          # Check database connectivity (if local deployment)
          if [ -z "$UAT_HOST" ]; then
            docker exec familycart-uat-db pg_isready -U familycart_uat -d familycart_uat || (echo "Database health check failed" && exit 1)
          fi

      - name: Run UAT integration tests
        working-directory: ./frontend
        env:
          UAT_BASE_URL: ${{ secrets.UAT_BASE_URL || 'http://localhost:3001' }}
          UAT_API_URL: ${{ secrets.UAT_API_URL || 'http://localhost:8001' }}
        run: |
          # Run basic integration tests against UAT environment
          npm run test:integration:uat || echo "Integration tests failed but deployment continues"

      - name: Notify deployment success
        if: success()
        run: |
          echo "‚úÖ UAT deployment successful!"
          echo "UAT environment is available at: http://uat.familycart.local"
          echo "Backend: ${{ needs.build.outputs.backend-image }}"
          echo "Frontend: ${{ needs.build.outputs.frontend-image }}"

  deploy-production:
    runs-on: self-hosted
    needs: [build, deploy-uat]
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Deploy to Production
        env:
          PRODUCTION_SSH_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}
          PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}
          PRODUCTION_USER: ${{ secrets.PRODUCTION_USER }}
          BACKEND_IMAGE: ${{ needs.build.outputs.backend-image }}
          FRONTEND_IMAGE: ${{ needs.build.outputs.frontend-image }}
        run: |
          # Prepare SSH key
          echo "$PRODUCTION_SSH_KEY" > /tmp/production_key
          chmod 600 /tmp/production_key
          
          # Deploy to production server
          ssh -i /tmp/production_key -o StrictHostKeyChecking=no $PRODUCTION_USER@$PRODUCTION_HOST << EOF
            cd /opt/familycart
            
            # Update image references
            sed -i "s|ghcr.io/jenicek001/familycart-backend:.*|$BACKEND_IMAGE|g" docker-compose.app.yml
            sed -i "s|ghcr.io/jenicek001/familycart-frontend:.*|$FRONTEND_IMAGE|g" docker-compose.app.yml
            
            # Deploy with zero downtime
            docker compose -f docker-compose.app.yml pull
            docker compose -f docker-compose.app.yml up -d --remove-orphans
            
            # Health check
            sleep 30
            curl -f http://localhost:8000/health || exit 1
          EOF
          
          # Cleanup SSH key
          rm /tmp/production_key

      - name: Production health check
        env:
          PRODUCTION_URL: ${{ secrets.PRODUCTION_URL }}
        run: |
          # Wait for deployment to stabilize
          sleep 60
          
          # Check production endpoint
          curl -f $PRODUCTION_URL/health || (echo "Production health check failed" && exit 1)
          
          # Optional: Run production smoke tests
          curl -f $PRODUCTION_URL/ || (echo "Production frontend check failed" && exit 1)

  performance-test:
    runs-on: self-hosted
    needs: deploy-uat
    if: github.ref == 'refs/heads/develop'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Wait for UAT stabilization
        run: sleep 120
        
      - name: Run load tests against UAT
        run: |
          # Install k6 if not available
          if ! command -v k6 &> /dev/null; then
            sudo apt-get update
            sudo apt-get install -y gnupg software-properties-common
            sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
            echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
            sudo apt-get update
            sudo apt-get install k6
          fi
          
          # Run performance tests
          cd scripts
          k6 run --env UAT_BASE_URL=http://localhost:3001 load-test.js
          
      - name: Archive performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: scripts/results/
          retention-days: 30

  cleanup:
    runs-on: self-hosted
    needs: [deploy-uat, deploy-production, performance-test]
    if: always()
    steps:
      - name: Clean up test services
        if: always()
        run: |
          echo "üßπ Cleaning up test services..."
          
          # NOTE: CI infrastructure databases are persistent and managed separately
          # No need to stop them as they're shared across builds
          
          # Additional resource cleanup to prevent runner crashes
          echo "üßπ Safe additional Docker cleanup..."
          timeout 30 docker system prune -f || true
          
          echo "üìä Final system resources:"
          free -h | grep -E '(Mem|Swap)' || true
          df -h / | tail -1 || true
          
      - name: Clean up Docker resources
        run: |
          # Check if Docker is available before attempting cleanup
          if command -v docker &> /dev/null && docker info &> /dev/null; then
            echo "Docker is available, performing cleanup..."
            # Remove old images (keep last 5 versions)
            docker image prune -af --filter "until=168h" || echo "Docker image prune failed, continuing..."
            
            # Clean up build cache
            docker buildx prune -af --filter "until=168h" || echo "Docker buildx prune failed, continuing..."
            
            echo "‚úÖ Docker cleanup completed"
          else
            echo "‚ö†Ô∏è  Docker not available or daemon not running, skipping Docker cleanup"
          fi
          
      - name: System maintenance
        run: |
          # Clean up logs
          sudo journalctl --vacuum-time=7d || true
          
          # Update system packages (exclude Docker to avoid runner disruption)
          sudo apt-get update || true
          sudo apt-mark hold docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin || true
          sudo apt-get upgrade -y --allow-downgrades -o Dpkg::Options::="--force-confdef" -o Dpkg::Options::="--force-confold" || true
          sudo apt-mark unhold docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin || true
          
          echo "‚úÖ System maintenance completed (Docker packages held to prevent runner disruption)"